{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda60515",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3702bb57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingRegressor, RandomForestRegressor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error, r2_score\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c3fb9",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from Dropbox URL\n",
    "data = pd.read_csv('https://www.dropbox.com/scl/fi/yis5zpl35tyn2r3z4d7uf/real_estate_market_data.csv?rlkey=oa1106yj6knt6w1oufogdpequ&st=571k3go0&dl=1')\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Columns: {data.shape[1]}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82cc85",
   "metadata": {},
   "source": [
    "## Step 3: Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check numerical vs categorical columns\n",
    "num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns: {len(num_cols)}\")\n",
    "print(f\"Categorical columns: {len(cat_cols)}\")\n",
    "print(f\"Total features: {len(num_cols) + len(cat_cols) - 1}\")  # -1 for Sale_Price\n",
    "\n",
    "print(f\"\\nTarget variable (Sale_Price) statistics:\")\n",
    "print(data['Sale_Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967269e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing = data.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fabab",
   "metadata": {},
   "source": [
    "## Step 4: Preprocessing — Separate Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target variable\n",
    "y = data['Sale_Price']\n",
    "X = data.drop(columns=['Sale_Price'])\n",
    "\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed588b4",
   "metadata": {},
   "source": [
    "## Step 5: Encode Categorical Variables & Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical variables with Label Encoding\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Encoding {len(cat_cols)} categorical columns...\")\n",
    "\n",
    "le_dict = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = X[col].fillna('Missing')\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    le_dict[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in numerical columns\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in num_cols:\n",
    "    if X[col].isnull().any():\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(\"✓ Preprocessing complete!\")\n",
    "print(f\"Features after encoding: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6eb4a",
   "metadata": {},
   "source": [
    "## Step 6: Feature Engineering — Create 13 New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadde584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Create 13 new features\n",
    "X['Total_SF'] = X['Gr_Liv_Area'] + X['Total_Bsmt_SF']\n",
    "X['Total_Bath'] = X['Full_Bath'] + 0.5 * X['Half_Bath'] + X['Bsmt_Full_Bath'] + 0.5 * X['Bsmt_Half_Bath']\n",
    "X['Age'] = X['Year_Sold'] - X['Year_Built']\n",
    "X['Remod_Age'] = X['Year_Sold'] - X['Year_Remod_Add']\n",
    "X['Total_Porch_SF'] = X['Wood_Deck_SF'] + X['Open_Porch_SF'] + X['Enclosed_Porch'] + X['Screen_Porch']\n",
    "X['Has_Pool'] = (X['Pool_Area'] > 0).astype(int)\n",
    "X['Has_Garage'] = (X['Garage_Area'] > 0).astype(int)\n",
    "X['Has_Basement'] = (X['Total_Bsmt_SF'] > 0).astype(int)\n",
    "X['Quality_SF'] = X['Gr_Liv_Area'] * X['Overall_Cond']\n",
    "X['Garage_to_Living'] = X['Garage_Area'] / (X['Gr_Liv_Area'] + 1)\n",
    "X['Lot_to_Living'] = X['Lot_Area'] / (X['Gr_Liv_Area'] + 1)\n",
    "X['Total_Rooms'] = X['TotRms_AbvGrd'] + X['Bedroom_AbvGr'] + X['Kitchen_AbvGr']\n",
    "X['Bed_Bath_Ratio'] = X['Bedroom_AbvGr'] / (X['Full_Bath'] + 0.5 * X['Half_Bath'] + 0.1)\n",
    "\n",
    "print(f\"✓ Added 13 engineered features\")\n",
    "print(f\"Total features now: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c1119",
   "metadata": {},
   "source": [
    "## Step 7: Log Transform Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform the target variable\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Visualize the transformation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(y, bins=50, edgecolor='black')\n",
    "axes[0].set_title('Original Sale_Price Distribution')\n",
    "axes[0].set_xlabel('Sale Price ($)')\n",
    "\n",
    "axes[1].hist(y_log, bins=50, edgecolor='black', color='green')\n",
    "axes[1].set_title('Log-Transformed Sale_Price Distribution')\n",
    "axes[1].set_xlabel('Log(Sale Price + 1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Log transformation helps normalize the skewed distribution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea85df12",
   "metadata": {},
   "source": [
    "## Step 8: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "_, _, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3bc03a",
   "metadata": {},
   "source": [
    "## Step 9: Define MAPE Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(\"MAPE function defined!\")\n",
    "print(\"Formula: MAPE = mean(|actual - predicted| / actual) * 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326401cc",
   "metadata": {},
   "source": [
    "## Step 10: Model Comparison — Train 4 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e41788",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. Random Forest (baseline approach)\n",
    "print(\"\\n1. Training Random Forest...\")\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_mape = mape(y_test, rf_pred)\n",
    "results['Random Forest'] = rf_mape\n",
    "print(f\"   MAPE: {rf_mape:.4f}%\")\n",
    "\n",
    "# 2. Gradient Boosting\n",
    "print(\"\\n2. Training Gradient Boosting...\")\n",
    "gb = GradientBoostingRegressor(n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "gb.fit(X_train, y_train_log)\n",
    "gb_pred = np.expm1(gb.predict(X_test))\n",
    "gb_mape = mape(y_test, gb_pred)\n",
    "results['Gradient Boosting'] = gb_mape\n",
    "print(f\"   MAPE: {gb_mape:.4f}%\")\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"\\n3. Training XGBoost...\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train_log, eval_set=[(X_test, y_test_log)], verbose=False)\n",
    "xgb_pred = np.expm1(xgb_model.predict(X_test))\n",
    "xgb_mape = mape(y_test, xgb_pred)\n",
    "results['XGBoost'] = xgb_mape\n",
    "print(f\"   MAPE: {xgb_mape:.4f}%\")\n",
    "\n",
    "# 4. LightGBM\n",
    "print(\"\\n4. Training LightGBM...\")\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=500, max_depth=8, learning_rate=0.05,\n",
    "    num_leaves=50, subsample=0.8, colsample_bytree=0.8,\n",
    "    random_state=42, n_jobs=-1, verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train_log)\n",
    "lgb_pred = np.expm1(lgb_model.predict(X_test))\n",
    "lgb_mape = mape(y_test, lgb_pred)\n",
    "results['LightGBM'] = lgb_mape\n",
    "print(f\"   MAPE: {lgb_mape:.4f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22214221",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2870e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "models = list(results.keys())\n",
    "mapes = list(results.values())\n",
    "colors = ['green' if m < 9.91 else 'red' for m in mapes]\n",
    "\n",
    "bars = plt.barh(models, mapes, color=colors, edgecolor='black')\n",
    "plt.axvline(x=9.91, color='red', linestyle='--', linewidth=2, label='Target: 9.91%')\n",
    "plt.xlabel('MAPE (%)')\n",
    "plt.title('Model Comparison - MAPE Scores')\n",
    "plt.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, mapes):\n",
    "    plt.text(val + 0.1, bar.get_y() + bar.get_height()/2, f'{val:.2f}%', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest model: {min(results, key=results.get)} with MAPE: {min(results.values()):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1daec1",
   "metadata": {},
   "source": [
    "## Step 12: Tuned XGBoost (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Tuned XGBoost...\")\n",
    "\n",
    "xgb_tuned = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_tuned.fit(X_train, y_train_log, eval_set=[(X_test, y_test_log)], verbose=False)\n",
    "\n",
    "# Predictions\n",
    "xgb_tuned_pred = np.expm1(xgb_tuned.predict(X_test))\n",
    "xgb_tuned_mape = mape(y_test, xgb_tuned_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TUNED XGBOOST RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MAPE: {xgb_tuned_mape:.4f}%\")\n",
    "print(f\"Target: 9.91%\")\n",
    "print(f\"Improvement: {9.91 - xgb_tuned_mape:.4f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213c696",
   "metadata": {},
   "source": [
    "## Step 13: 5-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running 5-Fold Cross-Validation...\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_mapes = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    y_train_log_cv = np.log1p(y_train_cv)\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=1000, max_depth=5, learning_rate=0.02,\n",
    "        subsample=0.7, colsample_bytree=0.7,\n",
    "        reg_alpha=0.1, reg_lambda=1.0, min_child_weight=3,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train_cv, y_train_log_cv, verbose=False)\n",
    "\n",
    "    y_pred_cv = np.expm1(model.predict(X_val_cv))\n",
    "    fold_mape = mape(y_val_cv, y_pred_cv)\n",
    "    cv_mapes.append(fold_mape)\n",
    "    print(f\"Fold {fold+1}: MAPE = {fold_mape:.4f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CROSS-VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mean MAPE:  {np.mean(cv_mapes):.4f}% ± {np.std(cv_mapes):.4f}%\")\n",
    "print(f\"Target:     9.91%\")\n",
    "print(f\"Improvement: {9.91 - np.mean(cv_mapes):.4f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167833e9",
   "metadata": {},
   "source": [
    "## Step 14: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from tuned model\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': xgb_tuned.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_20 = importance_df.head(20)\n",
    "plt.barh(top_20['Feature'], top_20['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941c45d",
   "metadata": {},
   "source": [
    "## Step 15: Load Prediction Data (New/Unseen Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction data\n",
    "predictions = pd.read_csv('https://www.dropbox.com/scl/fi/aol0myehwcdo093zvu0j5/real_estate_predictions.csv?rlkey=uhap0mzv2bnra08hocn96ezrz&st=88j2x1g4&dl=1')\n",
    "\n",
    "# Or load from local file:\n",
    "# predictions = pd.read_csv('real_estate_predictions.csv')\n",
    "\n",
    "print(f\"Prediction data shape: {predictions.shape}\")\n",
    "print(f\"\\nSale_Price column has {predictions['Sale_Price'].isna().sum()} missing values (out of {len(predictions)})\")\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc47062",
   "metadata": {},
   "source": [
    "## Step 16: Preprocess Prediction Data (Same Pipeline as Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1719fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess prediction data (same steps as training)\n",
    "X_pred = predictions.drop(columns=['Sale_Price'])\n",
    "\n",
    "# Encode categorical variables using saved encoders\n",
    "cat_cols = X_pred.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    X_pred[col] = X_pred[col].fillna('Missing')\n",
    "    known = set(le_dict[col].classes_)\n",
    "    X_pred[col] = X_pred[col].apply(lambda x: x if x in known else 'Missing')\n",
    "    X_pred[col] = le_dict[col].transform(X_pred[col])\n",
    "\n",
    "# Fill missing numerical values\n",
    "num_cols = X_pred.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in num_cols:\n",
    "    X_pred[col] = X_pred[col].fillna(X[col].median())\n",
    "\n",
    "# Add engineered features (same 13 features)\n",
    "X_pred['Total_SF'] = X_pred['Gr_Liv_Area'] + X_pred['Total_Bsmt_SF']\n",
    "X_pred['Total_Bath'] = X_pred['Full_Bath'] + 0.5 * X_pred['Half_Bath'] + X_pred['Bsmt_Full_Bath'] + 0.5 * X_pred['Bsmt_Half_Bath']\n",
    "X_pred['Age'] = X_pred['Year_Sold'] - X_pred['Year_Built']\n",
    "X_pred['Remod_Age'] = X_pred['Year_Sold'] - X_pred['Year_Remod_Add']\n",
    "X_pred['Total_Porch_SF'] = X_pred['Wood_Deck_SF'] + X_pred['Open_Porch_SF'] + X_pred['Enclosed_Porch'] + X_pred['Screen_Porch']\n",
    "X_pred['Has_Pool'] = (X_pred['Pool_Area'] > 0).astype(int)\n",
    "X_pred['Has_Garage'] = (X_pred['Garage_Area'] > 0).astype(int)\n",
    "X_pred['Has_Basement'] = (X_pred['Total_Bsmt_SF'] > 0).astype(int)\n",
    "X_pred['Quality_SF'] = X_pred['Gr_Liv_Area'] * X_pred['Overall_Cond']\n",
    "X_pred['Garage_to_Living'] = X_pred['Garage_Area'] / (X_pred['Gr_Liv_Area'] + 1)\n",
    "X_pred['Lot_to_Living'] = X_pred['Lot_Area'] / (X_pred['Gr_Liv_Area'] + 1)\n",
    "X_pred['Total_Rooms'] = X_pred['TotRms_AbvGrd'] + X_pred['Bedroom_AbvGr'] + X_pred['Kitchen_AbvGr']\n",
    "X_pred['Bed_Bath_Ratio'] = X_pred['Bedroom_AbvGr'] / (X_pred['Full_Bath'] + 0.5 * X_pred['Half_Bath'] + 0.1)\n",
    "\n",
    "# Ensure same columns as training\n",
    "X_pred = X_pred.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "print(f\"✓ Preprocessed {X_pred.shape[0]} samples with {X_pred.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d6eb9",
   "metadata": {},
   "source": [
    "## Step 17: Train Final Model on Full Data & Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d48fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on ALL training data\n",
    "print(\"Training final model on full dataset...\")\n",
    "\n",
    "final_model = xgb.XGBRegressor(\n",
    "    n_estimators=1000, max_depth=5, learning_rate=0.02,\n",
    "    subsample=0.7, colsample_bytree=0.7,\n",
    "    reg_alpha=0.1, reg_lambda=1.0, min_child_weight=3,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "final_model.fit(X, y_log, verbose=False)\n",
    "\n",
    "# Generate predictions\n",
    "pred_log = final_model.predict(X_pred)\n",
    "pred_prices = np.expm1(pred_log)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "predictions['Sale_Price'] = pred_prices\n",
    "\n",
    "print(f\"\\n✓ Generated {len(pred_prices)} predictions\")\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Min:    ${pred_prices.min():,.0f}\")\n",
    "print(f\"  Max:    ${pred_prices.max():,.0f}\")\n",
    "print(f\"  Mean:   ${pred_prices.mean():,.0f}\")\n",
    "print(f\"  Median: ${np.median(pred_prices):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bf470",
   "metadata": {},
   "source": [
    "## Step 18: Save Predictions & Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ed908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "predictions.to_csv('team_predictions.csv', index=False)\n",
    "print(\"✓ Predictions saved to 'team_predictions.csv'\")\n",
    "\n",
    "# Preview\n",
    "predictions[['Neighborhood', 'Gr_Liv_Area', 'TotRms_AbvGrd', 'Bldg_Type', 'Sale_Price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c960b3",
   "metadata": {},
   "source": [
    "## Step 19: MAPE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0248fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('MAPE Analysis Dashboard — Diyouva Christa Novith\\nReal Estate Price Prediction',\n",
    "             fontsize=16, fontweight='bold', y=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ec65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Model Comparison Bar Chart\n",
    "ax1 = axes[0, 0]\n",
    "all_models = list(results.keys()) + ['Tuned XGBoost']\n",
    "all_mapes = list(results.values()) + [xgb_tuned_mape]\n",
    "colors = ['#2ecc71' if m < 9.91 else '#e74c3c' for m in all_mapes]\n",
    "\n",
    "bars = ax1.barh(all_models, all_mapes, color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax1.axvline(x=9.91, color='red', linestyle='--', linewidth=2, label='Target: 9.91%')\n",
    "ax1.set_xlabel('MAPE (%)', fontsize=11)\n",
    "ax1.set_title('Model Comparison — MAPE Scores', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='lower right', fontsize=10)\n",
    "for bar, val in zip(bars, all_mapes):\n",
    "    ax1.text(val + 0.05, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.2f}%', va='center', fontsize=10, fontweight='bold')\n",
    "ax1.set_xlim(0, max(all_mapes) + 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Cross-Validation MAPE per Fold\n",
    "ax2 = axes[0, 1]\n",
    "fold_names = [f'Fold {i+1}' for i in range(5)]\n",
    "fold_colors = ['#3498db'] * 5\n",
    "cv_mean = np.mean(cv_mapes)\n",
    "cv_std = np.std(cv_mapes)\n",
    "\n",
    "bars2 = ax2.bar(fold_names, cv_mapes, color=fold_colors, edgecolor='black', linewidth=0.5)\n",
    "ax2.axhline(y=cv_mean, color='#e67e22', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {cv_mean:.2f}% ± {cv_std:.2f}%')\n",
    "ax2.axhline(y=9.91, color='red', linestyle=':', linewidth=2, label='Target: 9.91%')\n",
    "ax2.fill_between(range(-1, 6), cv_mean - cv_std, cv_mean + cv_std,\n",
    "                 alpha=0.15, color='#e67e22')\n",
    "ax2.set_xlabel('Fold', fontsize=11)\n",
    "ax2.set_ylabel('MAPE (%)', fontsize=11)\n",
    "ax2.set_title('5-Fold Cross-Validation MAPE', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.set_ylim(6.5, 10.5)\n",
    "for bar, val in zip(bars2, cv_mapes):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, val + 0.05,\n",
    "             f'{val:.2f}%', ha='center', fontsize=9, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1516ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: MAPE Improvement Over Target\n",
    "ax3 = axes[1, 0]\n",
    "target = 9.91\n",
    "improvements = [target - m for m in all_mapes]\n",
    "imp_colors = ['#27ae60' if v > 0 else '#c0392b' for v in improvements]\n",
    "\n",
    "bars3 = ax3.barh(all_models, improvements, color=imp_colors, edgecolor='black', linewidth=0.5)\n",
    "ax3.axvline(x=0, color='black', linewidth=1)\n",
    "ax3.set_xlabel('Improvement over Target (%)', fontsize=11)\n",
    "ax3.set_title('MAPE Improvement vs Target (9.91%)', fontsize=13, fontweight='bold')\n",
    "for bar, val in zip(bars3, improvements):\n",
    "    offset = 0.03 if val >= 0 else -0.03\n",
    "    ha = 'left' if val >= 0 else 'right'\n",
    "    ax3.text(val + offset, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:+.2f}%', va='center', ha=ha, fontsize=10, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: Prediction Distribution on New Data\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(pred_prices, bins=20, edgecolor='black', color='#9b59b6', alpha=0.7)\n",
    "ax4.axvline(x=pred_prices.mean(), color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: ${pred_prices.mean():,.0f}')\n",
    "ax4.axvline(x=np.median(pred_prices), color='green', linestyle='--', linewidth=2,\n",
    "            label=f'Median: ${np.median(pred_prices):,.0f}')\n",
    "ax4.set_xlabel('Predicted Sale Price ($)', fontsize=11)\n",
    "ax4.set_ylabel('Frequency', fontsize=11)\n",
    "ax4.set_title('Predicted Price Distribution (New Data)', fontsize=13, fontweight='bold')\n",
    "ax4.legend(fontsize=9)\n",
    "ax4.ticklabel_format(style='plain', axis='x')\n",
    "ax4.tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea0aaa",
   "metadata": {},
   "source": [
    "## Step 20: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17224c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL SUMMARY — Diyouva Christa Novith\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n MODEL RESULTS (Test Set MAPE):\")\n",
    "for name, score in results.items():\n",
    "    status = \"✓\" if score < 9.91 else \"✗\"\n",
    "    print(f\"  {status} {name:25s} → MAPE: {score:.4f}%\")\n",
    "print(f\"  ✓ {'Tuned XGBoost':25s} → MAPE: {xgb_tuned_mape:.4f}%  ← BEST\")\n",
    "\n",
    "print(f\"\\n CROSS-VALIDATION:\")\n",
    "print(f\"  Mean MAPE: {np.mean(cv_mapes):.4f}% ± {np.std(cv_mapes):.4f}%\")\n",
    "\n",
    "print(f\"\\n TARGET: 9.91%\")\n",
    "print(f\"  Best improvement: {9.91 - xgb_tuned_mape:.4f}%\")\n",
    "\n",
    "print(f\"\\n PREDICTIONS ON NEW DATA (100 properties):\")\n",
    "print(f\"  Mean:   ${pred_prices.mean():,.0f}\")\n",
    "print(f\"  Median: ${np.median(pred_prices):,.0f}\")\n",
    "print(f\"  Range:  ${pred_prices.min():,.0f} — ${pred_prices.max():,.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
